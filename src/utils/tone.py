import os
import asyncio
from openai import AsyncOpenAI

oai = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

DETECT_PROMPT = """Analyze this English transcript from a live stream/video and determine the speaker's tone and register.

TRANSCRIPT:
{text}

Based on the language style, choose exactly ONE of these Korean speech levels that would best match the speaker's tone:

1. casual - í•´ì²´/ë°˜ë§ (friends talking, gaming streams, very relaxed)
   Use when: slang, filler words, addressing chat directly, cursing, incomplete sentences
   
2. casual_polite - í•´ìš”ì²´ (friendly but polite, most YouTube content)
   Use when: conversational but structured, educational but approachable
   
3. formal - í•©ë‹ˆë‹¤ì²´ (news, lectures, business presentations)
   Use when: professional vocabulary, structured speech, formal setting
   
4. narrative - í•˜ë‹¤ì²´ (documentaries, storytelling, essays)
   Use when: descriptive, third person, explaining concepts with authority

Respond with ONLY the tone name (casual, casual_polite, formal, or narrative). Nothing else."""

TONE_INSTRUCTIONS = {
    "casual": (
        "Use casual Korean (í•´ì²´/ë°˜ë§). Examples: ~í•´, ~í–ˆì–´, ~í• ê²Œ, ~ì¸ë°, ~ê±°ë“ , ~ìž–ì•„, ~ìž„, ~ã…‹ã…‹. "
        "Sound natural like talking to friends or streaming. No formal endings."
    ),
    "casual_polite": (
        "Use casual polite Korean (í•´ìš”ì²´). Examples: ~í•´ìš”, ~í–ˆì–´ìš”, ~í•  ê±°ì˜ˆìš”, ~ì´ì—ìš”. "
        "Friendly but polite tone."
    ),
    "formal": (
        "Use formal polite Korean (í•©ë‹ˆë‹¤ì²´). Examples: ~í•©ë‹ˆë‹¤, ~í–ˆìŠµë‹ˆë‹¤, ~í•˜ê² ìŠµë‹ˆë‹¤. "
        "Maintain professional, respectful tone throughout."
    ),
    "narrative": (
        "Use written/narrative Korean (í•˜ë‹¤ì²´). Examples: ~í•œë‹¤, ~í–ˆë‹¤, ~í•  ê²ƒì´ë‹¤, ~ì´ë‹¤. "
        "Maintain a descriptive, storytelling tone."
    ),
}


class ToneDetector:
    def __init__(self):
        self.word_buffer: list[str] = []
        self.current_tone = "casual_polite"  # Default
        self.detected = False
        self._detecting = False
        self._detect_task: asyncio.Task | None = None

    def feed_text(self, text: str):
        """Feed transcript text. Triggers detection after ~50 words."""
        if self.detected:
            return

        words = text.split()
        self.word_buffer = words  # Keep latest full partial

        if len(self.word_buffer) >= 30 and not self._detecting:
            self._detecting = True
            self._detect_task = asyncio.create_task(self._detect())

    async def _detect(self):
        text = " ".join(self.word_buffer[-100:])
        try:
            response = await oai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "user", "content": DETECT_PROMPT.format(text=text)},
                ],
                temperature=0,
                max_tokens=10,
            )

            result = response.choices[0].message.content.strip().lower()

            if result in TONE_INSTRUCTIONS:
                old = self.current_tone
                self.current_tone = result
                self.detected = True
                print(f"ðŸŽ­ Tone detected: {old} â†’ {result} (from {len(self.word_buffer)}w)")
            else:
                print(f"ðŸŽ­ Tone detection unclear: '{result}', keeping {self.current_tone}")
                self._detecting = False  # Retry later

        except Exception as e:
            print(f"ðŸŽ­ Tone detection error: {e}")
            self._detecting = False

    def get_tone_instruction(self) -> str:
        return TONE_INSTRUCTIONS.get(self.current_tone, TONE_INSTRUCTIONS["casual_polite"])